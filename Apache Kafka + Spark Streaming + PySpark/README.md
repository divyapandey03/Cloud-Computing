# Introduction:

Apache Kafka is a distributed data store optimized for ingesting and processing streaming data in real-time. Streaming data is data that is continuously generated by thousands of data sources, which typically send the data records in simultaneously. A streaming platform needs to handle this constant influx of data, and process the data sequentially and incrementally.

Kafka provides three main functions to its users:

- Publish and subscribe to streams of records
- Effectively store streams of records in the order in which records were generated
- Process streams of records in real time


Kafka is primarily used to build real-time streaming data pipelines and applications that adapt to the data streams. It combines messaging, storage, and stream processing to allow storage and analysis of both historical and real-time data.  

We use Apache Kafka in a Linux environment in GCP Platform and reveals how events are consumed and produced using a Kafka-Python.The following diagram illustrates the Kafka ecosystem weâ€™re going to set up.

<img width="553" alt="kafkaimage" src="https://user-images.githubusercontent.com/23255126/205745054-63ed168b-f050-48b4-9cbf-3089f193787e.png">
